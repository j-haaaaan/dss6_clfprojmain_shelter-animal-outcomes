{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.combine import *\n",
    "from imblearn.over_sampling import *\n",
    "from imblearn.under_sampling import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint as sp_randint\n",
    "import numpy as np\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. param= { 'n_estimators' : [100,200,300,400,500,600,700,800,900],\n",
    "         'learning_rate' : [0.01,0.05,1.0,1.5,2.0,2.5,3.0],\n",
    "         'max_depth' : [3,4,5,6,7]\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 언더샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : TomekLinks\n",
      "XGBoost :  {'learning_rate': 0.099999999999999992, 'max_depth': 7, 'n_estimators': 110}\n",
      "train score: -0.5293616865841884\n",
      "test score: -0.8433441601249745\n",
      "log loss: 0.8433441601249745\n",
      "\n",
      "Wall time: 45min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "n_estimators = list(np.arange(50,151,10))\n",
    "learning_rate = list(np.arange(0.01,0.13,0.01))\n",
    "max_depth = [3,4,5,6,7,8,9]\n",
    "\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : TomekLinks')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= {'n_estimators' : n_estimators ,\n",
    "            'learning_rate' : learning_rate ,\n",
    "            'max_depth' : max_depth\n",
    "           }\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = TomekLinks(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : OneSidedSelection\n",
      "XGBoost :  {'learning_rate': 0.069999999999999993, 'max_depth': 7, 'n_estimators': 150}\n",
      "train score: -0.5324246155834526\n",
      "test score: -0.8447549785319242\n",
      "log loss: 0.8447549785319242\n",
      "\n",
      "Wall time: 44min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_estimators = list(np.arange(50,151,10))\n",
    "learning_rate = list(np.arange(0.01,0.13,0.01))\n",
    "max_depth = [3,4,5,6,7,8,9]\n",
    "\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : OneSidedSelection')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= {'n_estimators' : n_estimators ,\n",
    "            'learning_rate' : learning_rate ,\n",
    "            'max_depth' : max_depth\n",
    "           }\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = OneSidedSelection(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오버샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : ADASYN\n",
      "XGBoost :  {'learning_rate': 0.080000000000000002, 'max_depth': 4, 'n_estimators': 450}\n",
      "train score: -0.5217376174557616\n",
      "test score: -0.8217058350824629\n",
      "log loss: 0.8217058350824629\n",
      "\n",
      "Wall time: 28min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_estimators = list(np.arange(350,451,10))\n",
    "learning_rate = list(np.arange(0.01,0.1,0.01))\n",
    "max_depth = [4]\n",
    "                \n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : ADASYN')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= {'n_estimators' : n_estimators,\n",
    "            'learning_rate' : learning_rate,\n",
    "            'max_depth' : max_depth\n",
    "           }\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = ADASYN(ratio = 'minority',random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
