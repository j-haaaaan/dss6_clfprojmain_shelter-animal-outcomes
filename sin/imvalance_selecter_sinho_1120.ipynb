{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.combine import *\n",
    "from imblearn.over_sampling import *\n",
    "from imblearn.under_sampling import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint as sp_randint\n",
    "import numpy as np\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 언더샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : RandomUnderSampler\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.878695627267162\n",
      "test score: -1.2120638348033028\n",
      "log loss: 1.2120638348033028\n",
      "\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : RandomUnderSampler')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = RandomUnderSampler(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = RandomUnderSampler(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : TomekLinks\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.7251771088756608\n",
      "test score: -0.8483367239716572\n",
      "log loss: 0.8483367239716572\n",
      "\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : TomekLinks')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = TomekLinks(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = TomekLinks(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CondensedNearestNeighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : CondensedNearestNeighbour\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.9661839500334193\n",
      "test score: -0.969635800686705\n",
      "log loss: 0.969635800686705\n",
      "\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : CondensedNearestNeighbour')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = CondensedNearestNeighbour(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 33.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = CondensedNearestNeighbour(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : OneSidedSelection\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.7263688124250864\n",
      "test score: -0.8492100672506717\n",
      "log loss: 0.8492100672506717\n",
      "\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : OneSidedSelection')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = OneSidedSelection(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\prototype_selection\\one_sided_selection.py:197: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  idx_maj_extracted = np.delete(idx_maj, idx_maj_sample, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = OneSidedSelection(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : EditedNearestNeighbours\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.2759586630901983\n",
      "test score: -1.2348221376983555\n",
      "log loss: 1.2348221376983555\n",
      "\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : EditedNearestNeighbours')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = EditedNearestNeighbours(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = EditedNearestNeighbours(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NeighbourhoodCleaningRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : NeighbourhoodCleaningRule\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.47400507761038224\n",
      "test score: -1.0056581044604918\n",
      "log loss: 1.0056581044604918\n",
      "\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : NeighbourhoodCleaningRule')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = NeighbourhoodCleaningRule(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = NeighbourhoodCleaningRule(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오버샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : RandomOverSampler\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -1.0228018723955208\n",
      "test score: -1.0835411517442664\n",
      "log loss: 1.0835411517442664\n",
      "\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : RandomOverSampler')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = RandomOverSampler(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 21.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = RandomOverSampler(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : ADASYN\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.6644230309532677\n",
      "test score: -0.8745810331058764\n",
      "log loss: 0.8745810331058764\n",
      "\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : ADASYN')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = ADASYN(ratio = 'minority',random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y =  ADASYN(ratio = 'minority',random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : SMOTE\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.8277837696861409\n",
      "test score: -0.9217500570947348\n",
      "log loss: 0.9217500570947348\n",
      "\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : SMOTE')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = SMOTE(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8498913152328835\n",
      "\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = SMOTE(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 복합샘플링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : SMOTEENN\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.5231346654950687\n",
      "test score: -1.366697772760151\n",
      "log loss: 1.366697772760151\n",
      "\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : SMOTEENN')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = SMOTEENN(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8503676246932516\n",
      "\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20, shuffle = True)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = SMOTEENN(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : SMOTETomek\n",
      "XGBoost :  {'n_estimators': 100}\n",
      "train score: -0.7944025310495435\n",
      "test score: -0.9446675039917019\n",
      "log loss: 0.9446675039917019\n",
      "\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def model_cv(X_train, X_test, y_train, y_test, model_xgb, name):\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print('Sampling name : SMOTETomek')\n",
    "    print(name,': ',model_xgb.best_params_)\n",
    "    pred_y = model_xgb.predict_proba(X_test)\n",
    "    print('train score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "    print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "    print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "    print()\n",
    "\n",
    "def xgbc(X_train, X_test, y_train, y_test):\n",
    "    param= { 'n_estimators' : [100]}\n",
    "    model_xgb = GridSearchCV(XGBClassifier(), param, scoring=\"neg_log_loss\",n_jobs = 4)\n",
    "    name = 'XGBoost'\n",
    "    return model_cv(X_train, X_test, y_train, y_test, model_xgb, name)\n",
    "\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y = SMOTETomek(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "xgbc(final_X, X_test, y, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 20 , split_test_size = 0.5\n",
      "log loss: 0.8505592053293443\n",
      "\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_imb = pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(20, shuffle = True)\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','YearMonth', 'Month' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.5, random_state=0, shuffle=True)\n",
    "X, y = NeighbourhoodCleaningRule(random_state=0).fit_sample(X_train, y_train)\n",
    "df_final = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb_imb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb_imb.fit(df_final, y)\n",
    "\n",
    "print('cv = 20 , split_test_size = 0.5')\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb_imb, X_test, y_test, scoring=\"neg_log_loss\", cv=cv))))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling name : SMOTETomek\n",
      "train score: 0.7000801924619086\n",
      "test score: 0.6130440204514278\n",
      "log loss: 0.9446675039917019\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 4, 5. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 2 3 4]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    319\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    322\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             return_times=True)\n\u001b[1;32m--> 195\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    142\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   1684\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[0;32m   1685\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1686\u001b[1;33m                                                   lb.classes_))\n\u001b[0m\u001b[0;32m   1687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 4, 5. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 2 3 4]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_imb= pd.read_csv('df_pre.csv')\n",
    "del df_imb['Unnamed: 0']\n",
    "\n",
    "\n",
    "columns=['SexuponOutcome','Color_pre','DayuponOutcome','Breed_pre','Name','DateTime' ,'AnimalType','BreedMix']\n",
    "\n",
    "df_imb_x = df_imb[columns]\n",
    "df_imb_y = df_imb.iloc[:, [3]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_imb_x, df_imb_y, test_size = 0.3, random_state=0, shuffle=True)\n",
    "\n",
    "X, y =  SMOTETomek(random_state=0).fit_sample(X_train, y_train)\n",
    "final_X = pd.DataFrame(X, columns=columns)\n",
    "\n",
    "model_xgb = xgboost.XGBClassifier(n_estimators=100)\n",
    "model_xgb.fit(final_X, y)\n",
    "\n",
    "print('Sampling name : SMOTETomek')\n",
    "pred_y = model_xgb.predict_proba(X_test)\n",
    "print('train score: {}'.format(model_xgb.score(final_X, y)))\n",
    "print('test score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "print('log loss: {}'.format(log_loss(y_test, pred_y)))\n",
    "print()\n",
    "\n",
    "print('log loss: {}'.format(np.mean(-cross_val_score(model_xgb, X_test, y_test, scoring=\"neg_log_loss\", cv=KFold(20, shuffle=True)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
